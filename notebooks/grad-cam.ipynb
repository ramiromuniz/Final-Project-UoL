{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b00978f",
   "metadata": {},
   "source": [
    "## Grad-CAM Visual Explanations\n",
    "\n",
    "Up to this point we have trained and evaluated our models (MobileNetV2 and DenseNet121) using standard metrics such as accuracy, precision, recall and AUC.  \n",
    "While these numbers are useful, they don’t tell us **where** the model is looking in the image when making its decision.  \n",
    "\n",
    "To add explainability, we use **Grad-CAM (Gradient-weighted Class Activation Mapping)**.  \n",
    "This method produces a heatmap that highlights the areas of a mammogram image that most influenced the model’s prediction.  \n",
    "\n",
    "The outputs we generate here will help us:\n",
    "- Confirm if the model is focusing on the correct regions (e.g. lesion areas).\n",
    "- Inspect both correct and incorrect predictions (True Positives, True Negatives, False Positives, False Negatives).\n",
    "- Provide clear visuals for the final report and evaluation chapter.\n",
    "\n",
    "The following cells implement Grad-CAM and display three panels for each selected case:\n",
    "1. The original input image.  \n",
    "2. The heatmap of important regions.  \n",
    "3. An overlay of the heatmap on top of the original image.  \n",
    "\n",
    "These visualisations give us a more intuitive understanding of the model’s behaviour, beyond raw metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5ab5eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV dir exists: True\n",
      "JPEG dir exists: True\n"
     ]
    }
   ],
   "source": [
    "# --- Core ---\n",
    "import os, glob, random, json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- ML / DL ---\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# --- Keras (we’ll import DenseNet later) ---\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# --- Project paths ---\n",
    "\n",
    "ROOT = Path(r\"d:\\Computer Science\\UoL\\Final Project\\breast-cancer-detection\")\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "DATA_CSV_DIR = DATA_DIR / \"csv\"\n",
    "DATA_JPEG_DIR = DATA_DIR / \"kaggle/jpeg\"\n",
    "\n",
    "# Checks\n",
    "print(\"CSV dir exists:\", DATA_CSV_DIR.exists())\n",
    "print(\"JPEG dir exists:\", DATA_JPEG_DIR.exists())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
