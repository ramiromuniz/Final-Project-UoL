{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f37d51e1",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection Using Convolutional Neural Networks\n",
    "\n",
    "# Breast Cancer Detection Using Pre-trained Convolutional Neural Networks\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project explores whether deep learning can help radiologists detect breast cancer in mammograms more accurately. We use the **CBIS-DDSM dataset**, a curated subset of the Digital Database for Screening Mammography, which contains annotated images of breast tissue with known outcomes (benign or malignant).\n",
    "\n",
    "Instead of building a deep learning model from scratch, we use **MobileNetV2**, a pre-trained convolutional neural network originally trained on millions of general images (ImageNet). We apply **transfer learning**, keeping the lower layers (which extract basic patterns like edges and textures) and re-training only the final classification layers on the mammogram images.\n",
    "\n",
    "MobileNetV2 is a lightweight yet powerful architecture, ideal for fast experimentation and limited datasets like CBIS-DDSM. This approach helps us leverage existing computer vision knowledge while tailoring the model to the specific task of medical image classification.\n",
    "\n",
    "The goal is to build a **binary classifier** that can distinguish between benign and malignant findings. If successful, this prototype could serve as the foundation for clinical decision support tools that improve diagnostic accuracy and reduce human error in breast cancer screening.\n",
    "\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The Curated Breast Imaging Subset of DDSM (CBIS-DDSM) provides mammographic images with expert radiologist annotations. The dataset includes two types of abnormalities:\n",
    "\n",
    "- **Calcifications**: Small calcium deposits appearing as bright spots\n",
    "- **Masses**: Larger tissue abnormalities with varying shapes and densities\n",
    "\n",
    "Each case includes pathological ground truth labels enabling supervised learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629dc984",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Setup\n",
    "\n",
    "The first phase involves loading the necessary libraries and establishing the dataset structure. The CBIS-DDSM data is organized into CSV metadata files containing case information and JPEG directories containing the actual mammographic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477779a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Required libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "BASE_PATH = Path('../data/kaggle')\n",
    "CSV_PATH = BASE_PATH / 'csv'\n",
    "JPEG_PATH = BASE_PATH / 'jpeg'\n",
    "\n",
    "print(\"Data path configuration:\")\n",
    "print(f\"Base directory: {BASE_PATH}\")\n",
    "print(f\"CSV files: {CSV_PATH}\")\n",
    "print(f\"Image files: {JPEG_PATH}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if BASE_PATH.exists():\n",
    "    print(\"Data paths verified\")\n",
    "else:\n",
    "    print(\"Warning: Data directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27e5df",
   "metadata": {},
   "source": [
    "## Dataset Structure Exploration\n",
    "\n",
    "Understanding the dataset organization is essential before processing. This section examines the available files and their structure to inform subsequent data handling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab958279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine available CSV metadata files\n",
    "csv_files = list(CSV_PATH.glob('*.csv'))\n",
    "\n",
    "print(\"Available metadata files:\")\n",
    "for file in csv_files:\n",
    "    file_size = file.stat().st_size / 1024\n",
    "    print(f\"- {file.name} ({file_size:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nTotal files: {len(csv_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21574a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DICOM information file\n",
    "dicom_info = pd.read_csv(CSV_PATH / 'dicom_info.csv')\n",
    "\n",
    "print(\"DICOM Information Dataset:\")\n",
    "print(f\"Shape: {dicom_info.shape}\")\n",
    "print(f\"Columns: {list(dicom_info.columns)}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(dicom_info.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b24525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image series types\n",
    "print(\"Series Description Analysis:\")\n",
    "series_counts = dicom_info['SeriesDescription'].value_counts()\n",
    "\n",
    "for series_type, count in series_counts.items():\n",
    "    percentage = (count / len(dicom_info)) * 100\n",
    "    print(f\"- {series_type}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nStudy Description Analysis:\")\n",
    "study_counts = dicom_info['StudyDescription'].value_counts()\n",
    "for study_type, count in study_counts.items():\n",
    "    print(f\"- {study_type}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a87aff",
   "metadata": {},
   "source": [
    "## Data Cleaning and Path Correction\n",
    "\n",
    "The raw dataset requires preprocessing to remove unnecessary columns and correct file paths for the local environment. This ensures data quality and compatibility with the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62313db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean DICOM information dataset\n",
    "print(\"Data cleaning:\")\n",
    "print(f\"Original shape: {dicom_info.shape}\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1',\n",
    "    'Modality', 'StudyDescription'\n",
    "]\n",
    "\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in dicom_info.columns]\n",
    "dicom_info_clean = dicom_info.drop(columns=existing_columns_to_drop)\n",
    "\n",
    "print(f\"Cleaned shape: {dicom_info_clean.shape}\")\n",
    "print(f\"Removed columns: {existing_columns_to_drop}\")\n",
    "print(f\"Remaining columns: {list(dicom_info_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d649eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct image paths for local directory structure\n",
    "print(\"Path correction:\")\n",
    "\n",
    "# Show original path format\n",
    "original_path = dicom_info_clean['image_path'].iloc[0]\n",
    "print(f\"Original: {original_path}\")\n",
    "\n",
    "# Update paths to match local structure\n",
    "dicom_info_clean['image_path_corrected'] = dicom_info_clean['image_path'].apply(\n",
    "    lambda x: x.replace('CBIS-DDSM/jpeg', str(JPEG_PATH))\n",
    ")\n",
    "\n",
    "corrected_path = dicom_info_clean['image_path_corrected'].iloc[0]\n",
    "print(f\"Corrected: {corrected_path}\")\n",
    "\n",
    "# Verify path correction\n",
    "sample_size = min(50, len(dicom_info_clean))\n",
    "existing_paths = sum(1 for path in dicom_info_clean['image_path_corrected'].head(sample_size) \n",
    "                    if Path(path).exists())\n",
    "\n",
    "print(f\"Verification: {existing_paths}/{sample_size} paths exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c766519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for cropped images (optimal for CNN training)\n",
    "TARGET_IMAGE_TYPE = 'cropped images'\n",
    "cropped_images = dicom_info_clean[dicom_info_clean['SeriesDescription'] == TARGET_IMAGE_TYPE].copy()\n",
    "\n",
    "print(f\"Image filtering results:\")\n",
    "print(f\"Original dataset: {len(dicom_info_clean):,} images\")\n",
    "print(f\"Cropped images: {len(cropped_images):,} images\")\n",
    "print(f\"Retention rate: {len(cropped_images)/len(dicom_info_clean)*100:.1f}%\")\n",
    "\n",
    "print(\"\\nFiltered dataset sample:\")\n",
    "display(cropped_images[['PatientID', 'image_path_corrected']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915eacbf",
   "metadata": {},
   "source": [
    "## Clinical Case Information Loading\n",
    "\n",
    "The clinical case descriptions contain pathological information required for supervised learning. These files provide ground truth labels for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d56caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clinical case descriptions\n",
    "print(\"Loading clinical case information:\")\n",
    "\n",
    "# Load calcification cases\n",
    "calc_cases = pd.read_csv(CSV_PATH / 'calc_case_description_train_set.csv')\n",
    "print(f\"Calcification cases: {calc_cases.shape}\")\n",
    "\n",
    "# Load mass cases\n",
    "mass_cases = pd.read_csv(CSV_PATH / 'mass_case_description_train_set.csv')\n",
    "print(f\"Mass cases: {mass_cases.shape}\")\n",
    "\n",
    "print(f\"Total clinical cases: {len(calc_cases) + len(mass_cases):,}\")\n",
    "\n",
    "print(\"\\nCalcification cases sample:\")\n",
    "display(calc_cases.head(3))\n",
    "\n",
    "print(\"\\nMass cases sample:\")\n",
    "display(mass_cases.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3bc8b",
   "metadata": {},
   "source": [
    "## Data Loading Summary\n",
    "\n",
    "The dataset has been successfully loaded and prepared for analysis. The following components are now available:\n",
    "\n",
    "- **Image metadata**: Cleaned DICOM information with corrected file paths\n",
    "- **Filtered images**: Cropped images suitable for CNN training\n",
    "- **Clinical labels**: Pathological information for both calcification and mass cases\n",
    "\n",
    "This foundation enables the next phase of data preprocessing and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53bd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data loading summary\n",
    "print(\"Data Loading Complete\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Cropped images available: {len(cropped_images):,}\")\n",
    "print(f\"Unique patients: {cropped_images['PatientID'].nunique():,}\")\n",
    "print(f\"Calcification cases: {len(calc_cases):,}\")\n",
    "print(f\"Mass cases: {len(mass_cases):,}\")\n",
    "print(f\"Total clinical cases: {len(calc_cases) + len(mass_cases):,}\")\n",
    "\n",
    "print(\"\\nDataset ready for:\")\n",
    "print(\"- Label creation and validation\")\n",
    "print(\"- Image preprocessing and augmentation\") \n",
    "print(\"- Model training pipeline development\")\n",
    "\n",
    "print(\"\\nNext phase: Data preprocessing and model architecture design\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
